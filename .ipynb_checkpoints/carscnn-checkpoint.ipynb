{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f3482bc-8475-4e85-bbab-7e44fc2e163f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "\n",
    "train_data_path = '/Users/ummefahmidaakter/Downloads/cars/Train'\n",
    "val_data_path = '/Users/ummefahmidaakter/Downloads/cars/Test'\n",
    "\n",
    "# Define transforms to preprocess the data\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # resize the images to 224x224 pixels\n",
    "    transforms.ToTensor(),  # convert the images to PyTorch tensors\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # normalize the images\n",
    "])\n",
    "\n",
    "train_set = datasets.ImageFolder(root=train_data_path, transform=transform)\n",
    "val_set = datasets.ImageFolder(root=val_data_path, transform=transform)\n",
    "# Define the data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=16, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(val_set, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f648abb-af0c-4df6-95ca-8fd4cc53d9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Define the CNN model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64*28*28, 512)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(512, 3)  # 3 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.pool3(x)\n",
    "        x = x.view(-1, 64*28*28)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the CNN model\n",
    "model = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42fd857b-987a-449d-9ae4-f0af4707c80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=2.4968, Train Acc=0.2656, Kappa=0.1068, Val Loss=1.4888, Val Acc=0.0000\n",
      "Epoch 2: Train Loss=1.0887, Train Acc=0.3906, Kappa=0.0000, Val Loss=1.2624, Val Acc=0.0000\n",
      "Epoch 3: Train Loss=1.0618, Train Acc=0.3906, Kappa=0.0000, Val Loss=1.2991, Val Acc=0.0000\n",
      "Epoch 4: Train Loss=1.0001, Train Acc=0.4219, Kappa=0.0032, Val Loss=1.6184, Val Acc=0.0000\n",
      "Epoch 5: Train Loss=0.8904, Train Acc=0.5781, Kappa=0.0798, Val Loss=1.7396, Val Acc=0.0000\n",
      "Epoch 6: Train Loss=0.7884, Train Acc=0.6875, Kappa=0.4062, Val Loss=2.4089, Val Acc=0.0833\n",
      "Epoch 7: Train Loss=0.6658, Train Acc=0.8125, Kappa=0.7053, Val Loss=2.7993, Val Acc=0.0833\n",
      "Epoch 8: Train Loss=0.5639, Train Acc=0.8125, Kappa=0.6386, Val Loss=3.5896, Val Acc=0.0000\n",
      "Epoch 9: Train Loss=0.4046, Train Acc=0.8594, Kappa=0.7323, Val Loss=3.3268, Val Acc=0.0000\n",
      "Epoch 10: Train Loss=0.2702, Train Acc=0.9531, Kappa=0.9317, Val Loss=3.9149, Val Acc=0.0000\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Define a function to train the model for one epoch\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "# Loop through each fold using the indices generated by k-fold cross-validation\n",
    "def train_epoch(model, train_loader, criterion, optimizer):\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    # Loop over the training data\n",
    "    for images, labels in train_loader:\n",
    "        # Reset the gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "        # Add the loss for this batch to the total loss\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "        # Get the predicted labels\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # Calculate the accuracy for this batch and add it to the total accuracy\n",
    "        train_acc += torch.sum(predictions == labels.data)\n",
    "        # Store the true labels and predicted labels for later use\n",
    "        y_true.extend(labels.data.tolist())\n",
    "        y_pred.extend(predictions.tolist())\n",
    "    # Calculate the average training loss and accuracy\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    train_acc /= len(train_loader.dataset)\n",
    "    # Calculate the quadratic weighted Cohen's kappa score between two sets of labels\n",
    "    kappa = cohen_kappa_score(y_true, y_pred, weights='quadratic')\n",
    "    return train_loss, train_acc, kappa\n",
    "\n",
    "\n",
    "# Define a function to evaluate the model for one epoch\n",
    "def eval_epoch(model, val_loader, criterion):\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_acc = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            val_acc += torch.sum(predictions == labels.data)\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    val_acc /= len(val_loader.dataset)\n",
    "    return val_loss, val_acc\n",
    "# Define the number of epochs to train the model\n",
    "num_epochs = 10\n",
    "# Loop through each epoch\n",
    "for epoch in range(num_epochs):\n",
    "    # Train the model on the training set for one epoch\n",
    "    train_loss, train_acc, kappa = train_epoch(model, train_loader, criterion, optimizer)\n",
    "    # Evaluate the model on the validation set\n",
    "    val_loss, val_acc = eval_epoch(model, val_loader, criterion)\n",
    "    # Print the training and validation loss, accuracy, and kappa coefficient for the current epoch\n",
    "    print(f\"Epoch {epoch+1}: Train Loss={train_loss:.4f}, Train Acc={train_acc:.4f}, Kappa={kappa:.4f}, Val Loss={val_loss:.4f}, Val Acc={val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ba4dd55-81da-4a5f-af5e-dfce012e6ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr=0.001, batch_size=32\n",
      "Mean Val Acc=0.4582\n",
      "lr=0.001, batch_size=64\n",
      "Mean Val Acc=0.4873\n",
      "lr=0.0001, batch_size=32\n",
      "Mean Val Acc=0.5145\n",
      "lr=0.0001, batch_size=64\n",
      "Mean Val Acc=0.5318\n",
      "Best Hyperparameters: {'lr': 0.0001, 'batch_size': 64}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Define the k-fold cross-validation\n",
    "num_folds = 10\n",
    "kf = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "# Define the hyperparameters to search\n",
    "learning_rates = [0.001, 0.0001]\n",
    "batch_sizes = [32, 64]\n",
    "\n",
    "# Perform grid search over hyperparameters\n",
    "best_params = {}\n",
    "best_val_acc = 0.0\n",
    "for lr in learning_rates:\n",
    "    for batch_size in batch_sizes:\n",
    "        print(f\"lr={lr}, batch_size={batch_size}\")\n",
    "        fold = 0\n",
    "        val_accs = []\n",
    "        for train_indices, val_indices in kf.split(train_set):\n",
    "            fold += 1\n",
    "            # Split the dataset into training and validation sets for this fold\n",
    "            train_set_fold = torch.utils.data.Subset(train_set, train_indices)\n",
    "            val_set_fold = torch.utils.data.Subset(train_set, val_indices)\n",
    "            train_loader_fold = torch.utils.data.DataLoader(train_set_fold, batch_size=batch_size, shuffle=True)\n",
    "            val_loader_fold = torch.utils.data.DataLoader(val_set_fold, batch_size=batch_size, shuffle=False)\n",
    "            # Create a new instance of the CNN model for this fold\n",
    "            model = CNN()\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "            # Train the model for multiple epochs and evaluate its performance\n",
    "            num_epochs = 10\n",
    "            for epoch in range(num_epochs):\n",
    "                train_result = train_epoch(model, train_loader_fold, criterion, optimizer)\n",
    "                train_loss, train_acc = train_result[0], train_result[1]\n",
    "                val_loss, val_acc = eval_epoch(model, val_loader_fold, criterion)\n",
    "            val_accs.append(val_acc)\n",
    "        # Compute the mean validation accuracy over all folds\n",
    "        mean_val_acc = sum(val_accs) / num_folds\n",
    "        print(f\"Mean Val Acc={mean_val_acc:.4f}\")\n",
    "        # Update the best hyperparameters if necessary\n",
    "        if mean_val_acc > best_val_acc:\n",
    "            best_params[\"lr\"] = lr\n",
    "            best_params[\"batch_size\"] = batch_size\n",
    "            best_val_acc = mean_val_acc\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01e97180-0db8-46cf-9d90-df6f8ff450a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, Epoch 1: Train Loss=1.0258, Train Acc=0.1392, Val Loss=1.0388, Val Acc=0.6667\n",
      "Fold 1, Epoch 2: Train Loss=1.4803, Train Acc=0.4430, Val Loss=1.2366, Val Acc=0.3333\n",
      "Fold 1, Epoch 3: Train Loss=0.7270, Train Acc=0.5823, Val Loss=0.9523, Val Acc=0.3333\n",
      "Fold 1, Epoch 4: Train Loss=0.5539, Train Acc=0.7089, Val Loss=0.8293, Val Acc=0.2222\n",
      "Fold 1, Epoch 5: Train Loss=0.5700, Train Acc=0.7215, Val Loss=0.9212, Val Acc=0.3333\n",
      "Fold 1, Epoch 6: Train Loss=0.4693, Train Acc=0.7722, Val Loss=1.2700, Val Acc=0.3333\n",
      "Fold 1, Epoch 7: Train Loss=0.5188, Train Acc=0.7215, Val Loss=1.0974, Val Acc=0.3333\n",
      "Fold 1, Epoch 8: Train Loss=0.4129, Train Acc=0.8228, Val Loss=1.1629, Val Acc=0.1111\n",
      "Fold 1, Epoch 9: Train Loss=0.4436, Train Acc=0.8101, Val Loss=1.5378, Val Acc=0.2222\n",
      "Fold 1, Epoch 10: Train Loss=0.3788, Train Acc=0.8101, Val Loss=1.9921, Val Acc=0.3333\n",
      "\n",
      "Fold 1:\n",
      "Confusion matrix:\n",
      "[[0 6 0]\n",
      " [0 3 0]\n",
      " [0 0 0]]\n",
      "Accuracy: 0.3333\n",
      "Sensitivity: 1.0000\n",
      "Specificity: 0.0000\n",
      "Precision: 0.3333\n",
      "Recall: 1.0000\n",
      "F1 score: 0.5000\n",
      "Kappa: 0.0000\n",
      "Fold 2, Epoch 1: Train Loss=1.2035, Train Acc=0.4430, Val Loss=2.0743, Val Acc=0.3333\n",
      "Fold 2, Epoch 2: Train Loss=1.6126, Train Acc=0.4557, Val Loss=0.7975, Val Acc=0.4444\n",
      "Fold 2, Epoch 3: Train Loss=0.7244, Train Acc=0.5190, Val Loss=0.6098, Val Acc=0.6667\n",
      "Fold 2, Epoch 4: Train Loss=0.6879, Train Acc=0.5443, Val Loss=0.5980, Val Acc=0.6667\n",
      "Fold 2, Epoch 5: Train Loss=0.6110, Train Acc=0.6582, Val Loss=0.7161, Val Acc=0.5556\n",
      "Fold 2, Epoch 6: Train Loss=0.6380, Train Acc=0.5696, Val Loss=0.5741, Val Acc=0.5556\n",
      "Fold 2, Epoch 7: Train Loss=0.5201, Train Acc=0.7595, Val Loss=0.4907, Val Acc=0.6667\n",
      "Fold 2, Epoch 8: Train Loss=0.4837, Train Acc=0.7722, Val Loss=0.6877, Val Acc=0.5556\n",
      "Fold 2, Epoch 9: Train Loss=0.5370, Train Acc=0.6962, Val Loss=0.4856, Val Acc=0.7778\n",
      "Fold 2, Epoch 10: Train Loss=0.4495, Train Acc=0.7975, Val Loss=0.4503, Val Acc=0.6667\n",
      "\n",
      "Fold 2:\n",
      "Confusion matrix:\n",
      "[[1 2 0]\n",
      " [1 5 0]\n",
      " [0 0 0]]\n",
      "Accuracy: 0.6667\n",
      "Sensitivity: 0.8333\n",
      "Specificity: 0.3333\n",
      "Precision: 0.7143\n",
      "Recall: 0.8333\n",
      "F1 score: 0.7692\n",
      "Kappa: 0.1818\n",
      "Fold 3, Epoch 1: Train Loss=1.0838, Train Acc=0.4557, Val Loss=1.8628, Val Acc=0.4444\n",
      "Fold 3, Epoch 2: Train Loss=1.6316, Train Acc=0.4430, Val Loss=0.6822, Val Acc=0.5556\n",
      "Fold 3, Epoch 3: Train Loss=0.6606, Train Acc=0.5570, Val Loss=0.7382, Val Acc=0.5556\n",
      "Fold 3, Epoch 4: Train Loss=0.7240, Train Acc=0.5570, Val Loss=0.7163, Val Acc=0.5556\n",
      "Fold 3, Epoch 5: Train Loss=0.6848, Train Acc=0.5570, Val Loss=0.6187, Val Acc=0.7778\n",
      "Fold 3, Epoch 6: Train Loss=0.6039, Train Acc=0.7342, Val Loss=0.5809, Val Acc=0.6667\n",
      "Fold 3, Epoch 7: Train Loss=0.5402, Train Acc=0.6835, Val Loss=0.5958, Val Acc=0.7778\n",
      "Fold 3, Epoch 8: Train Loss=0.4887, Train Acc=0.7595, Val Loss=0.6507, Val Acc=0.5556\n",
      "Fold 3, Epoch 9: Train Loss=0.4622, Train Acc=0.7722, Val Loss=0.6735, Val Acc=0.5556\n",
      "Fold 3, Epoch 10: Train Loss=0.3852, Train Acc=0.8734, Val Loss=0.7870, Val Acc=0.5556\n",
      "\n",
      "Fold 3:\n",
      "Confusion matrix:\n",
      "[[2 2 0]\n",
      " [2 3 0]\n",
      " [0 0 0]]\n",
      "Accuracy: 0.5556\n",
      "Sensitivity: 0.6000\n",
      "Specificity: 0.5000\n",
      "Precision: 0.6000\n",
      "Recall: 0.6000\n",
      "F1 score: 0.6000\n",
      "Kappa: 0.1000\n",
      "Fold 4, Epoch 1: Train Loss=1.0108, Train Acc=0.1392, Val Loss=1.7397, Val Acc=0.7778\n",
      "Fold 4, Epoch 2: Train Loss=3.3663, Train Acc=0.5316, Val Loss=3.5420, Val Acc=0.2222\n",
      "Fold 4, Epoch 3: Train Loss=2.1416, Train Acc=0.4684, Val Loss=1.5843, Val Acc=0.2222\n",
      "Fold 4, Epoch 4: Train Loss=0.9257, Train Acc=0.5063, Val Loss=0.5186, Val Acc=0.7778\n",
      "Fold 4, Epoch 5: Train Loss=0.6558, Train Acc=0.5316, Val Loss=0.5233, Val Acc=0.7778\n",
      "Fold 4, Epoch 6: Train Loss=0.7081, Train Acc=0.5316, Val Loss=0.6127, Val Acc=0.7778\n",
      "Fold 4, Epoch 7: Train Loss=0.5944, Train Acc=0.6835, Val Loss=1.2011, Val Acc=0.2222\n",
      "Fold 4, Epoch 8: Train Loss=0.6924, Train Acc=0.5823, Val Loss=0.6625, Val Acc=0.6667\n",
      "Fold 4, Epoch 9: Train Loss=0.5101, Train Acc=0.7722, Val Loss=0.5019, Val Acc=0.7778\n",
      "Fold 4, Epoch 10: Train Loss=0.6051, Train Acc=0.5823, Val Loss=0.6314, Val Acc=0.7778\n",
      "\n",
      "Fold 4:\n",
      "Confusion matrix:\n",
      "[[1 1 0]\n",
      " [1 6 0]\n",
      " [0 0 0]]\n",
      "Accuracy: 0.7778\n",
      "Sensitivity: 0.8571\n",
      "Specificity: 0.5000\n",
      "Precision: 0.8571\n",
      "Recall: 0.8571\n",
      "F1 score: 0.8571\n",
      "Kappa: 0.3571\n",
      "Fold 5, Epoch 1: Train Loss=1.1868, Train Acc=0.1519, Val Loss=1.1326, Val Acc=0.5556\n",
      "Fold 5, Epoch 2: Train Loss=1.2964, Train Acc=0.4304, Val Loss=0.8038, Val Acc=0.4444\n",
      "Fold 5, Epoch 3: Train Loss=0.6730, Train Acc=0.5696, Val Loss=0.8407, Val Acc=0.4444\n",
      "Fold 5, Epoch 4: Train Loss=0.7000, Train Acc=0.5696, Val Loss=0.7720, Val Acc=0.4444\n",
      "Fold 5, Epoch 5: Train Loss=0.6764, Train Acc=0.6076, Val Loss=0.7670, Val Acc=0.4444\n",
      "Fold 5, Epoch 6: Train Loss=0.5554, Train Acc=0.6456, Val Loss=0.7656, Val Acc=0.4444\n",
      "Fold 5, Epoch 7: Train Loss=0.5141, Train Acc=0.7468, Val Loss=0.8055, Val Acc=0.4444\n",
      "Fold 5, Epoch 8: Train Loss=0.4614, Train Acc=0.7722, Val Loss=0.7581, Val Acc=0.4444\n",
      "Fold 5, Epoch 9: Train Loss=0.3891, Train Acc=0.8481, Val Loss=0.6062, Val Acc=0.5556\n",
      "Fold 5, Epoch 10: Train Loss=0.4552, Train Acc=0.7468, Val Loss=1.0123, Val Acc=0.4444\n",
      "\n",
      "Fold 5:\n",
      "Confusion matrix:\n",
      "[[0 5 0]\n",
      " [0 4 0]\n",
      " [0 0 0]]\n",
      "Accuracy: 0.4444\n",
      "Sensitivity: 1.0000\n",
      "Specificity: 0.0000\n",
      "Precision: 0.4444\n",
      "Recall: 1.0000\n",
      "F1 score: 0.6154\n",
      "Kappa: 0.0000\n",
      "Fold 6, Epoch 1: Train Loss=1.0265, Train Acc=0.1266, Val Loss=1.2520, Val Acc=0.5556\n",
      "Fold 6, Epoch 2: Train Loss=1.2052, Train Acc=0.5443, Val Loss=1.7524, Val Acc=0.4444\n",
      "Fold 6, Epoch 3: Train Loss=1.2994, Train Acc=0.5696, Val Loss=0.7990, Val Acc=0.4444\n",
      "Fold 6, Epoch 4: Train Loss=0.6437, Train Acc=0.6329, Val Loss=0.6821, Val Acc=0.5556\n",
      "Fold 6, Epoch 5: Train Loss=0.6797, Train Acc=0.5316, Val Loss=0.6502, Val Acc=0.6667\n",
      "Fold 6, Epoch 6: Train Loss=0.5646, Train Acc=0.7468, Val Loss=0.7671, Val Acc=0.4444\n",
      "Fold 6, Epoch 7: Train Loss=0.5402, Train Acc=0.6329, Val Loss=0.6401, Val Acc=0.6667\n",
      "Fold 6, Epoch 8: Train Loss=0.4959, Train Acc=0.6962, Val Loss=0.6639, Val Acc=0.5556\n",
      "Fold 6, Epoch 9: Train Loss=0.4120, Train Acc=0.7975, Val Loss=0.6083, Val Acc=0.6667\n",
      "Fold 6, Epoch 10: Train Loss=0.3916, Train Acc=0.7975, Val Loss=0.6301, Val Acc=0.6667\n",
      "\n",
      "Fold 6:\n",
      "Confusion matrix:\n",
      "[[4 1 0]\n",
      " [2 2 0]\n",
      " [0 0 0]]\n",
      "Accuracy: 0.6667\n",
      "Sensitivity: 0.5000\n",
      "Specificity: 0.8000\n",
      "Precision: 0.6667\n",
      "Recall: 0.5000\n",
      "F1 score: 0.5714\n",
      "Kappa: 0.3077\n",
      "Fold 7, Epoch 1: Train Loss=1.3668, Train Acc=0.3671, Val Loss=0.9742, Val Acc=0.5556\n",
      "Fold 7, Epoch 2: Train Loss=1.1469, Train Acc=0.4304, Val Loss=0.7641, Val Acc=0.5556\n",
      "Fold 7, Epoch 3: Train Loss=0.7810, Train Acc=0.4810, Val Loss=0.8251, Val Acc=0.4444\n",
      "Fold 7, Epoch 4: Train Loss=0.6982, Train Acc=0.6456, Val Loss=0.9745, Val Acc=0.4444\n",
      "Fold 7, Epoch 5: Train Loss=0.6718, Train Acc=0.5696, Val Loss=0.8525, Val Acc=0.4444\n",
      "Fold 7, Epoch 6: Train Loss=0.5668, Train Acc=0.6582, Val Loss=0.6528, Val Acc=0.5556\n",
      "Fold 7, Epoch 7: Train Loss=0.6093, Train Acc=0.6076, Val Loss=0.6220, Val Acc=0.7778\n",
      "Fold 7, Epoch 8: Train Loss=0.4978, Train Acc=0.7215, Val Loss=0.8478, Val Acc=0.4444\n",
      "Fold 7, Epoch 9: Train Loss=0.5157, Train Acc=0.7468, Val Loss=0.6523, Val Acc=0.5556\n",
      "Fold 7, Epoch 10: Train Loss=0.4257, Train Acc=0.7975, Val Loss=0.5607, Val Acc=0.8889\n",
      "\n",
      "Fold 7:\n",
      "Confusion matrix:\n",
      "[[5 0 0]\n",
      " [1 3 0]\n",
      " [0 0 0]]\n",
      "Accuracy: 0.8889\n",
      "Sensitivity: 0.7500\n",
      "Specificity: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 0.7500\n",
      "F1 score: 0.8571\n",
      "Kappa: 0.7692\n",
      "Fold 8, Epoch 1: Train Loss=1.3351, Train Acc=0.4304, Val Loss=2.2082, Val Acc=0.4444\n",
      "Fold 8, Epoch 2: Train Loss=2.0287, Train Acc=0.4430, Val Loss=0.6997, Val Acc=0.5556\n",
      "Fold 8, Epoch 3: Train Loss=0.6616, Train Acc=0.5696, Val Loss=0.7616, Val Acc=0.5556\n",
      "Fold 8, Epoch 4: Train Loss=0.7186, Train Acc=0.5570, Val Loss=0.7647, Val Acc=0.5556\n",
      "Fold 8, Epoch 5: Train Loss=0.6983, Train Acc=0.5570, Val Loss=0.7302, Val Acc=0.5556\n",
      "Fold 8, Epoch 6: Train Loss=0.6674, Train Acc=0.6076, Val Loss=0.7143, Val Acc=0.4444\n",
      "Fold 8, Epoch 7: Train Loss=0.5763, Train Acc=0.7468, Val Loss=0.9212, Val Acc=0.5556\n",
      "Fold 8, Epoch 8: Train Loss=0.6335, Train Acc=0.5570, Val Loss=0.7581, Val Acc=0.5556\n",
      "Fold 8, Epoch 9: Train Loss=0.4976, Train Acc=0.7722, Val Loss=0.7371, Val Acc=0.4444\n",
      "Fold 8, Epoch 10: Train Loss=0.5190, Train Acc=0.7215, Val Loss=0.7287, Val Acc=0.6667\n",
      "\n",
      "Fold 8:\n",
      "Confusion matrix:\n",
      "[[2 2 0]\n",
      " [1 4 0]\n",
      " [0 0 0]]\n",
      "Accuracy: 0.6667\n",
      "Sensitivity: 0.8000\n",
      "Specificity: 0.5000\n",
      "Precision: 0.6667\n",
      "Recall: 0.8000\n",
      "F1 score: 0.7273\n",
      "Kappa: 0.3077\n",
      "Fold 9, Epoch 1: Train Loss=1.0369, Train Acc=0.5125, Val Loss=2.9040, Val Acc=0.5000\n",
      "Fold 9, Epoch 2: Train Loss=2.7152, Train Acc=0.4375, Val Loss=1.1130, Val Acc=0.5000\n",
      "Fold 9, Epoch 3: Train Loss=0.9264, Train Acc=0.5625, Val Loss=1.1827, Val Acc=0.5000\n",
      "Fold 9, Epoch 4: Train Loss=0.9198, Train Acc=0.5625, Val Loss=0.7905, Val Acc=0.5000\n",
      "Fold 9, Epoch 5: Train Loss=0.7017, Train Acc=0.5625, Val Loss=0.7674, Val Acc=0.5000\n",
      "Fold 9, Epoch 6: Train Loss=0.7004, Train Acc=0.7125, Val Loss=0.6999, Val Acc=0.5000\n",
      "Fold 9, Epoch 7: Train Loss=0.5952, Train Acc=0.7250, Val Loss=0.8542, Val Acc=0.5000\n",
      "Fold 9, Epoch 8: Train Loss=0.6511, Train Acc=0.5625, Val Loss=0.6166, Val Acc=0.6250\n",
      "Fold 9, Epoch 9: Train Loss=0.5179, Train Acc=0.7625, Val Loss=0.6025, Val Acc=0.6250\n",
      "Fold 9, Epoch 10: Train Loss=0.4975, Train Acc=0.7375, Val Loss=0.6062, Val Acc=0.6250\n",
      "\n",
      "Fold 9:\n",
      "Confusion matrix:\n",
      "[[3 1 0]\n",
      " [2 2 0]\n",
      " [0 0 0]]\n",
      "Accuracy: 0.6250\n",
      "Sensitivity: 0.5000\n",
      "Specificity: 0.7500\n",
      "Precision: 0.6667\n",
      "Recall: 0.5000\n",
      "F1 score: 0.5714\n",
      "Kappa: 0.2500\n",
      "Fold 10, Epoch 1: Train Loss=1.0503, Train Acc=0.4875, Val Loss=6.8602, Val Acc=0.1250\n",
      "Fold 10, Epoch 2: Train Loss=3.5876, Train Acc=0.4750, Val Loss=0.5705, Val Acc=0.7500\n",
      "Fold 10, Epoch 3: Train Loss=0.7016, Train Acc=0.5625, Val Loss=0.3489, Val Acc=0.8750\n",
      "Fold 10, Epoch 4: Train Loss=0.8324, Train Acc=0.5250, Val Loss=0.5307, Val Acc=0.8750\n",
      "Fold 10, Epoch 5: Train Loss=0.6709, Train Acc=0.5375, Val Loss=0.6905, Val Acc=0.5000\n",
      "Fold 10, Epoch 6: Train Loss=0.6822, Train Acc=0.7250, Val Loss=0.6841, Val Acc=0.3750\n",
      "Fold 10, Epoch 7: Train Loss=0.6258, Train Acc=0.7125, Val Loss=0.7067, Val Acc=0.3750\n",
      "Fold 10, Epoch 8: Train Loss=0.5652, Train Acc=0.6750, Val Loss=0.9101, Val Acc=0.3750\n",
      "Fold 10, Epoch 9: Train Loss=0.5442, Train Acc=0.7125, Val Loss=0.9448, Val Acc=0.3750\n",
      "Fold 10, Epoch 10: Train Loss=0.4925, Train Acc=0.7500, Val Loss=0.5319, Val Acc=0.7500\n",
      "\n",
      "Fold 10:\n",
      "Confusion matrix:\n",
      "[[1 0 0]\n",
      " [2 5 0]\n",
      " [0 0 0]]\n",
      "Accuracy: 0.7500\n",
      "Sensitivity: 0.7143\n",
      "Specificity: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 0.7143\n",
      "F1 score: 0.8333\n",
      "Kappa: 0.3846\n",
      "\n",
      "Average Performance Metrics across all folds:\n",
      "Confusion Matrix:\n",
      " [[1 2 0]\n",
      " [1 3 0]\n",
      " [0 0 0]]\n",
      "Accuracy: 0.6375\n",
      "Sensitivity: 0.7555\n",
      "Specificity: 0.5383\n",
      "Precision: 0.6949\n",
      "Recall: 0.7555\n",
      "F1 score: 0.6902\n",
      "Kappa: 0.2658\n",
      "Best split: Fold 7\n"
     ]
    }
   ],
   "source": [
    "# part 3\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, cohen_kappa_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import torch.optim as optim\n",
    "from sklearn import metrics\n",
    "\n",
    "# Check if GPU is available, otherwise use CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define the number of epochs to train for\n",
    "num_epochs = 10\n",
    "\n",
    "# Define performance metric lists\n",
    "cms = []\n",
    "accs = []\n",
    "reports = []\n",
    "sensitivities = []\n",
    "specificities = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "results = []\n",
    "kappas = []\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "num_folds = 10\n",
    "kf = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "# Loop through each fold using the indices generated by k-fold cross-validation\n",
    "for fold, (train_indices, val_indices) in enumerate(kf.split(train_set)):\n",
    "    # Create the training and validation sets using the current fold indices\n",
    "    train_set_fold = torch.utils.data.Subset(train_set, train_indices)\n",
    "    val_set_fold = torch.utils.data.Subset(train_set, val_indices)\n",
    "\n",
    "    # Create the data loaders for the training and validation sets with a batch size of 64\n",
    "    train_loader = torch.utils.data.DataLoader(train_set_fold, batch_size=64, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_set_fold, batch_size=64, shuffle=False)\n",
    "\n",
    "    # Initialize a new instance of the CNN model, the CrossEntropyLoss criterion, and the Adam optimizer\n",
    "    model = CNN()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Train the model for the specified number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        # Train the model on the current fold training set for one epoch\n",
    "        train_loss, train_acc, kappa = train_epoch(model, train_loader, criterion, optimizer)\n",
    "        \n",
    "        # Evaluate the model on the current fold validation set\n",
    "        val_loss, val_acc = eval_epoch(model, val_loader, criterion)\n",
    "        \n",
    "        # Print the training and validation loss and accuracy for the current epoch and fold\n",
    "        print(f\"Fold {fold+1}, Epoch {epoch+1}: Train Loss={train_loss:.4f}, Train Acc={train_acc:.4f}, Val Loss={val_loss:.4f}, Val Acc={val_acc:.4f}\")\n",
    "\n",
    "    # Evaluate performance on validation set\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())  \n",
    "        cm = confusion_matrix(y_true, y_pred, labels=[0, 1, 2])\n",
    "        acc = np.sum(np.diag(cm)) / np.sum(cm)\n",
    "        report = classification_report(y_true, y_pred, zero_division=0)\n",
    "        tn = cm[0, 0]\n",
    "        fp = cm[0, 1]\n",
    "        fn = cm[1, 0]\n",
    "        tp = cm[1, 1]\n",
    "        sensitivity = tp / (tp + fn + 1e-10)\n",
    "        specificity = tn / (tn + fp + 1e-10)\n",
    "        precision = tp / (tp + fp + 1e-10)\n",
    "        recall = tp / (tp + fn + 1e-10)\n",
    "        f1 = 2 * (precision * recall) / (precision + recall)\n",
    "        kappa = cohen_kappa_score(y_true, y_pred)\n",
    "        \n",
    "        \n",
    "        # Append performance metrics to lists\n",
    "        cms.append(cm)\n",
    "        accs.append(acc)\n",
    "        sensitivities.append(sensitivity)\n",
    "        specificities.append(specificity)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        f1s.append(f1)\n",
    "        kappas.append(kappa)\n",
    "        \n",
    "        # Print performance metrics for current fold\n",
    "        print(f\"\\nFold {fold+1}:\")\n",
    "        print(\"Confusion matrix:\")\n",
    "        np.set_printoptions(threshold=np.inf)\n",
    "        print(cm)\n",
    "        print(f\"Accuracy: {acc:.4f}\")\n",
    "        print(f\"Sensitivity: {sensitivity:.4f}\")\n",
    "        print(f\"Specificity: {specificity:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1 score: {f1:.4f}\")\n",
    "        print(f\"Kappa: {kappa:.4f}\")\n",
    "        \n",
    "        # Append results to list\n",
    "        results.append({\n",
    "        'Fold': fold+1,\n",
    "        'Accuracy': acc,\n",
    "        'Confusion Matrix': cm,\n",
    "        'Sensitivity': sensitivity,\n",
    "        'Specificity': specificity,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1 Score': f1,\n",
    "        'Kappa': kappa\n",
    "        })\n",
    "\n",
    "# Calculate average performance metrics across all folds\n",
    "avg_cm = np.mean(np.array(cms), axis=0)\n",
    "avg_acc = np.mean(np.array(accs))\n",
    "avg_sensitivity = np.mean(np.array(sensitivities))\n",
    "avg_specificity = np.mean(np.array(specificities))\n",
    "avg_precision = np.mean(np.array(precisions))\n",
    "avg_recall = np.mean(np.array(recalls))\n",
    "avg_f1 = np.mean(np.array(f1s))\n",
    "avg_kappa = np.mean(np.array(kappas))\n",
    "\n",
    "# Print average performance metrics\n",
    "print(\"\\nAverage Performance Metrics across all folds:\")\n",
    "avg_cm = np.zeros((3, 3), dtype=int)\n",
    "for c in cms:\n",
    "    # Get the shape of the confusion matrix and use it to dynamically set the shape of the average confusion matrix\n",
    "    c_shape = c.shape\n",
    "    avg_cm += np.pad(c, [(0, 3 - c_shape[0]), (0, 3 - c_shape[1])], mode='constant', constant_values=0)\n",
    "avg_cm = avg_cm // num_folds\n",
    "tn = avg_cm[0, 0]\n",
    "fp = avg_cm[0, 1]\n",
    "fn = avg_cm[1, 0]\n",
    "tp = avg_cm[1, 1]\n",
    "print('Confusion Matrix:\\n', avg_cm)\n",
    "print(f\"Accuracy: {avg_acc:.4f}\")\n",
    "print(f\"Sensitivity: {avg_sensitivity:.4f}\")\n",
    "print(f\"Specificity: {avg_specificity:.4f}\")\n",
    "print(f\"Precision: {avg_precision:.4f}\")\n",
    "print(f\"Recall: {avg_recall:.4f}\")\n",
    "print(f\"F1 score: {avg_f1:.4f}\")\n",
    "print(f\"Kappa: {avg_kappa:.4f}\")\n",
    "#Find the split with the highest overall performance\n",
    "best_split = max(results, key=lambda x: (x['Accuracy'] + x['Sensitivity'] + x['Specificity'] + x['Precision'] + x['Recall'] + x['F1 Score'] + x['Kappa'] + np.sum(x['Confusion Matrix']))/8)\n",
    "print(f\"Best split: Fold {best_split['Fold']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69322f19-0a1c-4e0a-9e3a-7c0dd358c348",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
